# Function to add slight noise to text
def add_noise(text, noise_level=0.05):
    words = text.split()
    num_noisy_words = max(1, int(len(words) * noise_level))
    for _ in range(num_noisy_words):
        idx = random.randint(0, len(words) - 1)
        words[idx] = words[idx][::-1]  # Reverse a random word
    return " ".join(words)

# Function to clean and preprocess data
def load_and_preprocess_data(csv_path):
    df = pd.read_csv(csv_path, names=["english", "french"])
    df.dropna(inplace=True)
    df = df.sample(frac=1).reset_index(drop=True)  # Shuffle dataset
    df["english"] = df["english"].apply(lambda x: add_noise(x))
    df["french"] = df["french"].apply(lambda x: add_noise(x))
    return df

def train_cross_encoder(csv_path, epochs=5, batch_size=32, learning_rate=2e-5, model_folder_name="cross_encoder_model"):
    df = load_and_preprocess_data(csv_path)
    X = list(zip(df["english"], df["french"]))
    y = [1] * len(X)  # Assume all translations are correct
    split = int(0.9 * len(X))
    X_train, X_val = X[:split], X[split:]
    y_train, y_val = y[:split], y[split:]

    model = CrossEncoder('google-bert/bert-base-multilingual-uncased', num_labels=1)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.model.to(device)

    train_examples = [InputExample(texts=[sent1, sent2], label=float(label)) for (sent1, sent2), label in zip(X_train, y_train)]
    val_examples = [InputExample(texts=[sent1, sent2], label=float(label)) for (sent1, sent2), label in zip(X_val, y_val)]
    
    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)
    evaluator = CEBinaryClassificationEvaluator.from_input_examples(val_examples, name="validation")
    warmup_steps = math.ceil(len(train_dataloader) * epochs * 0.1)
    
    model.fit(
